{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cyntexia\\AppData\\Local\\Temp\\ipykernel_15040\\708864498.py:49: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs = gr.inputs.Image(label=\"Image of Crowd\")\n",
      "C:\\Users\\Cyntexia\\AppData\\Local\\Temp\\ipykernel_15040\\708864498.py:49: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs = gr.inputs.Image(label=\"Image of Crowd\")\n",
      "C:\\Users\\Cyntexia\\AppData\\Local\\Temp\\ipykernel_15040\\708864498.py:50: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs = [gr.outputs.Image(label=\"Predicted Density Map\",type = \"numpy\"), gr.outputs.Label(label=\"Predicted Count\",type = \"numpy\")]\n",
      "C:\\Users\\Cyntexia\\AppData\\Local\\Temp\\ipykernel_15040\\708864498.py:50: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'numpy'}\n",
      "  outputs = [gr.outputs.Image(label=\"Predicted Density Map\",type = \"numpy\"), gr.outputs.Label(label=\"Predicted Count\",type = \"numpy\")]\n",
      "C:\\Users\\Cyntexia\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\interface.py:328: UserWarning: The `allow_flagging` parameter in `Interface` nowtakes a string value ('auto', 'manual', or 'never'), not a boolean. Setting parameter to: 'never'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyntexia\\anaconda3\\envs\\gradio_app\\Lib\\site-packages\\torch\\nn\\functional.py:4079: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "c:\\Users\\Cyntexia\\anaconda3\\envs\\gradio_app\\Lib\\site-packages\\torch\\nn\\functional.py:4079: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from models import vgg19\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "#create a folder named pretrained_models\n",
    "#download the model using the url and save it in the above folder\n",
    "url = \"https://drive.google.com/file/d/11wsCnalTaElaAcXQFVMq4T7BKW6PLxnC/view?usp=sharing\"\n",
    "model_path = \"pretrained_models/model_sh_B.pth\"\n",
    "#model_path = r\"D:\\2023\\deploy cc model using gradio\\original dm count\\DM-Count-master\\pretrained_models\\model_sh_B.pth\"\n",
    "device = torch.device('cpu')  # device can be \"cpu\" or \"gpu\"\n",
    "\n",
    "model = vgg19()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_path, device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict(inp):\n",
    "    inp = Image.fromarray(inp.astype('uint8'), 'RGB')\n",
    "    #inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
    "    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    # Apply the transformation to the image\n",
    "    img_tensor = trans(inp)\n",
    "    # extra dimension for batch size\n",
    "    inp = img_tensor.unsqueeze(0)\n",
    "    inp = inp.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs, _ = model(inp)\n",
    "\n",
    "    count = torch.sum(outputs).item()\n",
    "    vis_img = outputs[0, 0].cpu().numpy()\n",
    "    # normalize density map values from 0 to 1, then map it to 0-255.\n",
    "    vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min() + 1e-5)\n",
    "    vis_img = (vis_img * 255).astype(np.uint8)\n",
    "    vis_img = cv2.applyColorMap(vis_img, cv2.COLORMAP_JET)\n",
    "    vis_img = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)\n",
    "    return vis_img, int(count)\n",
    "\n",
    "\n",
    "title = \"Crowd Counter\"\n",
    "desc = \"A demo of Crowd counting model\"\n",
    "examples = [\n",
    "    [\"images\\IMG_1.jpg\"],\n",
    "    [\"images\\IMG_2.jpg\"],\n",
    "    [\"images\\IMG_107.jpg\"],\n",
    "]\n",
    "inputs = gr.inputs.Image(label=\"Image of Crowd\")\n",
    "outputs = [gr.outputs.Image(label=\"Predicted Density Map\",type = \"numpy\"), gr.outputs.Label(label=\"Predicted Count\",type = \"numpy\")]\n",
    "gr.Interface(fn=predict, inputs=inputs, outputs=outputs, title=title, description=desc, examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
